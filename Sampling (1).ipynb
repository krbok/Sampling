{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment: 1 Sampling"
      ],
      "metadata": {
        "id": "xYZBoAE6aj8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7qQvXTYSYPvM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the imbalance Dataset into Balance Dataset with Oversampling method"
      ],
      "metadata": {
        "id": "D5Hy85iUaz0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZtqan50FsxI",
        "outputId": "8ab3230d-ca22-4a6b-d0d3-95636a8e3a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "majority_class = df[df['Class'] == 0]\n",
        "minority_class = df[df['Class'] == 1]\n",
        "\n",
        "\n",
        "balanced_minority = resample(minority_class,\n",
        "                             replace=True,\n",
        "                             n_samples=len(majority_class),\n",
        "                             random_state=42)\n",
        "\n",
        "balanced_df = pd.concat([majority_class, balanced_minority])\n",
        "\n",
        "print(balanced_df['Class'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.  Simple Random Sampling"
      ],
      "metadata": {
        "id": "KXvpcvF-bNcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_random_sample = balanced_df.sample(n=500, random_state=42)\n"
      ],
      "metadata": {
        "id": "vllQ-hzsagQj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Stratified Sampling"
      ],
      "metadata": {
        "id": "03GwY129bTWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "_, stratified_sample = train_test_split(balanced_df,\n",
        "                                        test_size=500/len(balanced_df),\n",
        "                                        stratify=balanced_df['Class'],\n",
        "                                        random_state=42)\n"
      ],
      "metadata": {
        "id": "g3C62ljWbbsx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Systematic Sampling"
      ],
      "metadata": {
        "id": "_JORzgpIbeIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "step = len(balanced_df) // 500\n",
        "systematic_sample = balanced_df.iloc[::step, :]\n"
      ],
      "metadata": {
        "id": "ENbePj0Bbjc_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Cluster Sampling"
      ],
      "metadata": {
        "id": "WZVrn96Cbo9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "bins = [0, 50, 100, 200, 500, np.inf]\n",
        "labels = [0, 1, 2, 3, 4]\n",
        "df['Cluster'] = pd.cut(df['Amount'], bins=bins, labels=labels)\n",
        "print(df['Cluster'].value_counts())\n",
        "np.random.seed(42)\n",
        "df['Cluster'] = np.random.randint(0, 5, size=len(df))\n",
        "print(df['Cluster'].value_counts())\n",
        "selected_clusters = np.random.choice(df['Cluster'].unique(), size=2, replace=False)\n",
        "cluster_sample = df[df['Cluster'].isin(selected_clusters)]\n",
        "\n",
        "print(cluster_sample.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4MTS8qbboCJ",
        "outputId": "b2a3d02c-9798-4d18-eb4d-dd754ce8ee32"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster\n",
            "0    560\n",
            "1     99\n",
            "2     51\n",
            "3     34\n",
            "4     23\n",
            "Name: count, dtype: int64\n",
            "Cluster\n",
            "0    163\n",
            "3    162\n",
            "4    160\n",
            "1    146\n",
            "2    141\n",
            "Name: count, dtype: int64\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
            "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
            "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
            "\n",
            "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
            "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
            "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
            "6  0.081213  0.464960  ... -0.270710 -0.154104 -0.780055  0.750137 -0.257237   \n",
            "7 -3.807864  0.615375  ... -1.015455  0.057504 -0.649709 -0.415267 -0.051634   \n",
            "8  0.851084 -0.392048  ... -0.268092 -0.204233  1.011592  0.373205 -0.384157   \n",
            "\n",
            "        V27       V28  Amount  Class  Cluster  \n",
            "0  0.133558 -0.021053  149.62      0        3  \n",
            "2 -0.055353 -0.059752  378.66      0        2  \n",
            "6  0.034507  0.005168    4.99      0        2  \n",
            "7 -1.206921 -1.085339   40.80      0        2  \n",
            "8  0.011747  0.142404   93.20      0        2  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Bootstrap Sampling"
      ],
      "metadata": {
        "id": "-KEx0nRCb_ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bootstrap_sample = balanced_df.sample(n=500, replace=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "bSBkbgG1bl6j"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Evaluate Sampling Techniques on Diverse ML Models"
      ],
      "metadata": {
        "id": "gq531TOkcszt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Support Vector Machine\": SVC(kernel='rbf', random_state=42)\n",
        "}\n",
        "\n",
        "sampling_methods = {\n",
        "    \"Simple Random\": simple_random_sample,\n",
        "    \"Stratified\": stratified_sample,\n",
        "    \"Systematic\": systematic_sample,\n",
        "    \"Cluster\": cluster_sample,\n",
        "    \"Bootstrap\": bootstrap_sample\n",
        "}\n",
        "\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for sampling_name, sample in sampling_methods.items():\n",
        "    X = sample.drop(columns=['Class'])\n",
        "    y = sample['Class']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        results[(sampling_name, model_name)] = acc\n",
        "\n",
        "\n",
        "for (sampling, model), accuracy in results.items():\n",
        "    print(f\"Sampling: {sampling}, Model: {model}, Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDDVRXhRcvcp",
        "outputId": "60fe1f31-1c2c-409a-9a1c-cc05e8a0c2db"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling: Simple Random, Model: Logistic Regression, Accuracy: 0.50\n",
            "Sampling: Simple Random, Model: Decision Tree, Accuracy: 0.50\n",
            "Sampling: Simple Random, Model: Random Forest, Accuracy: 0.50\n",
            "Sampling: Simple Random, Model: K-Nearest Neighbors, Accuracy: 0.50\n",
            "Sampling: Simple Random, Model: Support Vector Machine, Accuracy: 0.75\n",
            "Sampling: Stratified, Model: Logistic Regression, Accuracy: 0.93\n",
            "Sampling: Stratified, Model: Decision Tree, Accuracy: 0.98\n",
            "Sampling: Stratified, Model: Random Forest, Accuracy: 0.99\n",
            "Sampling: Stratified, Model: K-Nearest Neighbors, Accuracy: 0.94\n",
            "Sampling: Stratified, Model: Support Vector Machine, Accuracy: 0.70\n",
            "Sampling: Systematic, Model: Logistic Regression, Accuracy: 0.95\n",
            "Sampling: Systematic, Model: Decision Tree, Accuracy: 0.99\n",
            "Sampling: Systematic, Model: Random Forest, Accuracy: 1.00\n",
            "Sampling: Systematic, Model: K-Nearest Neighbors, Accuracy: 0.95\n",
            "Sampling: Systematic, Model: Support Vector Machine, Accuracy: 0.64\n",
            "Sampling: Cluster, Model: Logistic Regression, Accuracy: 1.00\n",
            "Sampling: Cluster, Model: Decision Tree, Accuracy: 1.00\n",
            "Sampling: Cluster, Model: Random Forest, Accuracy: 1.00\n",
            "Sampling: Cluster, Model: K-Nearest Neighbors, Accuracy: 1.00\n",
            "Sampling: Cluster, Model: Support Vector Machine, Accuracy: 1.00\n",
            "Sampling: Bootstrap, Model: Logistic Regression, Accuracy: 0.98\n",
            "Sampling: Bootstrap, Model: Decision Tree, Accuracy: 0.98\n",
            "Sampling: Bootstrap, Model: Random Forest, Accuracy: 1.00\n",
            "Sampling: Bootstrap, Model: K-Nearest Neighbors, Accuracy: 0.96\n",
            "Sampling: Bootstrap, Model: Support Vector Machine, Accuracy: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "table_data = [[\"Sampling Method\"] + list(models.keys())]\n",
        "for sampling in sampling_methods.keys():\n",
        "    row = [sampling]\n",
        "    for model in models.keys():\n",
        "        row.append(results.get((sampling, model), \"N/A\"))\n",
        "    table_data.append(row)\n",
        "\n",
        "\n",
        "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2TCY-lgdP8E",
        "outputId": "eff6b30f-b989-40b8-8c05-2aa05c38cff1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n",
            "| Sampling Method   |   Logistic Regression |   Decision Tree |   Random Forest |   K-Nearest Neighbors |   Support Vector Machine |\n",
            "+===================+=======================+=================+=================+=======================+==========================+\n",
            "| Simple Random     |              0.5      |        0.5      |        0.5      |              0.5      |                 0.75     |\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n",
            "| Stratified        |              0.930693 |        0.980198 |        0.990099 |              0.940594 |                 0.70297  |\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n",
            "| Systematic        |              0.95098  |        0.990196 |        1        |              0.95098  |                 0.637255 |\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n",
            "| Cluster           |              1        |        1        |        1        |              1        |                 1        |\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n",
            "| Bootstrap         |              0.98     |        0.98     |        1        |              0.96     |                 0.78     |\n",
            "+-------------------+-----------------------+-----------------+-----------------+-----------------------+--------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Undersampling\n",
        "\n",
        "\n",
        "majority_class = df[df['Class'] == 0]\n",
        "minority_class = df[df['Class'] == 1]\n",
        "\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "undersampled_majority = resample(\n",
        "    majority_class,\n",
        "    replace=False,\n",
        "    n_samples=len(minority_class),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "undersampled_df = pd.concat([undersampled_majority, minority_class])\n",
        "\n",
        "print(undersampled_df['Class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpibXajCeQis",
        "outputId": "3b7b1835-bbd1-44b1-f3b9-657345814af0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "0    9\n",
            "1    9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(undersampled_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUmet8fhfk7z",
        "outputId": "0a16dc9e-b17f-4673-e3e9-d5dc59986e17"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Random Sampling\n",
        "\n",
        "sample_size = min(100, len(undersampled_df))\n",
        "simple_random_sample = undersampled_df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "\n",
        "# Stratified Sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_size = len(undersampled_df)\n",
        "\n",
        "if dataset_size > 100:\n",
        "    test_size = 100 / dataset_size\n",
        "else:\n",
        "    test_size = max(1, dataset_size - 1)\n",
        "\n",
        "\n",
        "try:\n",
        "    _, stratified_sample = train_test_split(\n",
        "        undersampled_df,\n",
        "        test_size=test_size,\n",
        "        stratify=undersampled_df['Class'],\n",
        "        random_state=42\n",
        "    )\n",
        "    print(f\"Stratified Sample Size: {len(stratified_sample)}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error during stratified sampling: {e}\")\n",
        "\n",
        "print(f\"Stratified Sample Size: {len(stratified_sample)}\")\n",
        "dataset_size = len(undersampled_df)\n",
        "step = max(1, dataset_size // 100)\n",
        "\n",
        "\n",
        "try:\n",
        "    systematic_sample = undersampled_df.iloc[::step, :]\n",
        "    print(f\"Systematic Sample Size: {len(systematic_sample)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during systematic sampling: {e}\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "undersampled_df['Cluster'] = np.random.randint(0, 5, size=len(undersampled_df))\n",
        "selected_clusters = np.random.choice(undersampled_df['Cluster'].unique(), size=2, replace=False)\n",
        "cluster_sample = undersampled_df[undersampled_df['Cluster'].isin(selected_clusters)]\n",
        "\n",
        "\n",
        "bootstrap_sample = undersampled_df.sample(n=100, replace=True, random_state=42)\n",
        "\n",
        "\n",
        "sampling_methods = {\n",
        "    \"Simple Random\": simple_random_sample,\n",
        "    \"Stratified\": stratified_sample,\n",
        "    \"Systematic\": systematic_sample,\n",
        "    \"Cluster\": cluster_sample,\n",
        "    \"Bootstrap\": bootstrap_sample\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsGOVmyafsx1",
        "outputId": "76d2762c-cdd7-4952-ebd6-34578c5d3de6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during stratified sampling: The train_size = 1 should be greater or equal to the number of classes = 2\n",
            "Stratified Sample Size: 501\n",
            "Systematic Sample Size: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sampling_methods = {\n",
        "    \"Simple Random\": simple_random_sample,\n",
        "    \"Stratified\": stratified_sample,\n",
        "    \"Systematic\": systematic_sample,\n",
        "    \"Cluster\": cluster_sample,\n",
        "    \"Bootstrap\": bootstrap_sample\n",
        "}\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Support Vector Machine\": SVC(kernel='rbf', random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for sampling_name, sample in sampling_methods.items():\n",
        "    X = sample.drop(columns=['Class', 'Cluster'], errors='ignore')\n",
        "    y = sample['Class']\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "        acc = accuracy_score(y, y_pred)\n",
        "        results[(sampling_name, model_name)] = acc\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "results_df = pd.DataFrame(\n",
        "    [\n",
        "        {\"Sampling Method\": sampling, \"Model\": model, \"Accuracy\": accuracy}\n",
        "        for (sampling, model), accuracy in results.items()\n",
        "    ]\n",
        ")\n",
        "\n",
        "pivot_results = results_df.pivot(\n",
        "    index=\"Sampling Method\", columns=\"Model\", values=\"Accuracy\"\n",
        ")\n",
        "print(tabulate(pivot_results, headers=\"keys\", tablefmt=\"grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yURF3Vb2eah-",
        "outputId": "60d09cc9-ad9d-4cdc-df03-84d3fe118628"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n",
            "| Sampling Method   |   Decision Tree |   K-Nearest Neighbors |   Logistic Regression |   Random Forest |   Support Vector Machine |\n",
            "+===================+=================+=======================+=======================+=================+==========================+\n",
            "| Bootstrap         |               1 |              0.98     |               1       |               1 |                 0.65     |\n",
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n",
            "| Cluster           |               1 |              0.625    |               1       |               1 |                 0.75     |\n",
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n",
            "| Simple Random     |               1 |              0.611111 |               1       |               1 |                 0.666667 |\n",
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n",
            "| Stratified        |               1 |              0.968064 |               0.94012 |               1 |                 0.660679 |\n",
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n",
            "| Systematic        |               1 |              0.611111 |               1       |               1 |                 0.666667 |\n",
            "+-------------------+-----------------+-----------------------+-----------------------+-----------------+--------------------------+\n"
          ]
        }
      ]
    }
  ]
}